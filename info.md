# Проект: извлечение артикулов из бд
  
## Цель  
  
Автоматически находить в текстах объявлений артикулы и связанные с ними бренды, приводить текст и найденные значения к единому формату (регистры, латиница/кириллица, дефисы, спецсимволы) и сохранять результат в БД в структурированном виде (сырой и нормализованный текст, первый и все найденные артикулы, ближайший бренд, метаданные). Поиск — каскадный (сначала бренды → затем артикулы этих брендов) с базовой валидацией и дедупликацией результатов для повышения точности и производительности.

---  
  
## Исходные данные  
  
* **CSV-словарь**: файл (\~2 млн строк) со схемой: `id, article, brand`.  
* **БД**: `avito.public`  
      
  * `public.special_model_data` — `id, title, …`  
  * `public.text_model_data` — `id, description, characteristic, …`  
  
---  
  
## Подготовка данных (JOIN)  
  
Соединям таблицы через обычный join и берем значения  
  
Далее склеиваем: `text_raw = title || ' ' || description || ' ' || characteristic`.  
  
---  
  
## Нормализация  
  
### 1) Текст объявлений  
  
Для **поиска** применяем канон к `text_raw`:  
  
* `UPPERCASE`;  
* замена визуально схожих русских букв на латиницу: `А→A, В→B, Е→E, К→K, М→M, Н→H, О→O, Р→P, С→C, Т→T, У→Y, Х→X` и пр.;  + замена максимально заменить все русские буквы на латинские (к примеру Я на Y и так далее (по звучанию))
  Меняем только большие буквы, так как предварительно применяем UPPERCASE
* тире удаляем; прочие спецсимволы → пробелы;  
* **пробелы не схлопываем**.  
  
  
### 2) Артикулы  
  
* Для **поиска** те же правила, что и для текста, но **дефисы убираем только на время поиска**.  
* При записи в бд записываем вариант для поиска (но с исходными дефисами)
  
### 3) Бренды: чтение и дедупликация  
  
1. При чтении CSV собираем список `brand` и сразу нормализуем: `UPPERCASE`, обрезаем внешние и внутренние пробелы, приводим русские↔латинские к единому алфавиту.  
2. Удаляем дубли по нормализованной форме.  
3. У нас должны быть группы брендов (которые приравниваются) К примеру BRP =  SKIDOO = CANAM  . То есть SKIDOO и CANAM заменим на BRP



  
---  
  
## Логика сопоставления (конвейер)  
  
1. Ищем **бренды** в нормализованном тексте словарём (Aho–Corasick).  Важное уточнение, должна быть возможность создать списки приравниваемых брендов. Пример BRP это LYNX = ROTAX . То есть если в тексте есть слово LYNX, то мы меняем его на BRP
2. Сужаем поиск артикулов: берём **только** артикулы брендов, найденных в тексте.   
3. Ищем **артикулы** и формируем поля результата:  
  
   * `first_article` — первый найденный артикул 
   * `brand_near_first_article` — бренд, по которому идет данный артикул из автомата 
   * `all_articles` — все найденные артикулы 
   * `all_brands` — бренды, встретившиеся рядом с артикулами 
  
---  

  
## Поисковые техники ( необходимый набор)  
  
* **Aho–Corasick** (обязательно) для быстрого поиска шаблонов-кандидатов.  Используем библиотеку pyahocorasick в python (последнюю версию)
* 
*#1) Цели каскада

Сузить пространство поиска артикулов до брендов, реально встретившихся в тексте..

 --
 
 **Повысить точность** (меньше ложных срабатываний) и **ускорить** за счёт маленьких автоматов по нужным брендам (или группам брендов), которые ищут артикулы по брендам, вместо одного огромного. 

— Автомат Aho-Corasick по брендам находит все вхождения и фиксирует позиции.  
— Далее ищем артикулы _только_ по найденным брендам/группам брендов с помощью небольших специализированных автоматов.
— Меньше ложных срабатываний: фильтры минимальной длины (≥3 для цифр, ≥4 для буквенно-цифровых), дедупликация и отсев «слишком общих» паттернов.  
— Быстрее за счёт каскада и маленьких автоматов: поиск O(n), автоматы загружаются/переиспользуются один раз; вычислений становится на ~80–90% меньше.

**Итого:** один общий автомат по брендам → набор маленьких автоматов по артикулам для найденных брендов (или их семей), что одновременно повышает точность и даёт ускорение.

То есть сначала создаем один автомат с брендами и используем его для нахождения брендов в тексте. Затем для каждого бренда (группы брендов) строим автоматы с артикулами, относящимися к ним
 
 ----


# Хранение построенных автоматов (pickle)

**Зачем:** пересобирать Aho-Corasick-автоматы каждый раз дорого по времени; держим готовые pickle.ак как каждый раз строить автоматы с 0 затратно по времени

**Бренды:**  
— Один общий автомат для брендов, один файл (pickle).
Автоматы для артикулов нужно хранить в формате json (хешами объектов)
группами в формате [
  {
    "brand": "YAMAHA",
    "pickle_hash": "",          // хэш от: отсортированный список 
    "objects_count": 15342,            // сколько шаблонов вошло в автомат
    "created_at": "2025-08-20T12:34:56Z"
  }
]

Также должна быть система проверки актуальности автоматов (можно сделать такую проверя кол-во объектов в автомате по бренду)





Также нужно сделать так, чтобы была возможность одной командой (или одним простым действием) удалить все сохраненные автоматы (во время разработки для тестов)
  
---  
  
## Модель данных (целевой слой)  
  
`public.avito_parts_resolved`:  
  
* `ad_id` — номер объявления;  
* `text_clean` — нормализованный текст 
* `first_article` — первый найденный артикул 
* `brand_near_first_article` — бренд по которуму нашли первый артикул
* `all_articles` — массив артикулов найденных в тексте
* `all_brands` — массив брендов, артикулы которых найдены   
* *(опционально) дата обработки
  
---  
  
## Конфигурация (.env)  
  
* `MIN_ARTICLE_LEN_DIGITS` — минимальная длина артикула, если **только цифры**;  
* `MIN_ARTICLE_LEN_ALPHANUM` — минимальная длина артикула, если **содержит буквы**.  
  
---  
  
## Технологии и требования  
  
* Использовать библиотеку **Aho–Corasick** (например, `pyahocorasick`).  
* SQL: PostgreSQL; материализованное представление ; **JOIN** — обязательно.  
* Везде соблюдать правила нормализации: **пробелы не схлопывать**
* Все библиотеки должны быть самых актуальных версий
  
---  
  

